{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating regression lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, so far we have seen that our regression lines make an estimation of our values of $y$.  They are useful because we can make an estimation of an output given an input.  In our example, we can make an estimation of a movie's expected revenue given a budget.  Our regression lines are described by two different variables, $m$, which represents the slope of the line and $b$ which is the value of $y$ when $x$ is zero.\n",
    "\n",
    "So far we have been rather fast and loose with choosing our regression line.  We have either used data where our regression line perfectly matched our data, or have simply used the eyeball test to see that our regression line made sense.  Well today we're going further.  In this lesson, we'll learn how to evaluate the accuracy of a regression line, and how to use a technique to choose a better, or even \"best fit\" regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the accuracy of a regression line, we see how closely our regression line matches the data we have.  Let's find out what this means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_show = {'x': 0, 'y': 100}\n",
    "second_show = {'x': 100, 'y': 150}\n",
    "third_show = {'x': 200, 'y': 600}\n",
    "fourth_show = {'x': 400, 'y': 700}\n",
    "\n",
    "shows = [first_show, second_show, third_show, fourth_show]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's set a roughshod regression line simply by drawing a line between our first and last points.  Eventually, we'll improve this regression line, so it's ok that we don't use a rigorous technique right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. We write a method to calculate the slope between two points\n",
    "\n",
    "def slope_between_two_points(first_point, second_point):\n",
    "    return (second_point['y'] - first_point['y'])/(second_point['x'] - first_point['x'])\n",
    "\n",
    "# 2. Then apply this to our first and last points.  \n",
    "slope_between_two_points(shows[0], shows[3]) # 1.5\n",
    "    # So we'll use m = 1.5\n",
    "\n",
    "# 3. we have a point for where x = 0, so that can be our y-intercept \n",
    "def y_intercept(points):\n",
    "    point_at_zero = list(filter(lambda show: show['x'] == 0,shows))[0]\n",
    "    return point_at_zero['y']\n",
    "\n",
    "y_intercept(shows) # b = 100 \n",
    "\n",
    "\n",
    "# plugging m and b into our formula y = mx + b we get the following sample_regression_formula\n",
    "# m = 1.5\n",
    "# b = 100\n",
    "def sample_regression_formula(x):\n",
    "    return 1.5(x) + 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now that we have our sample regression formula we can see it in action.  We draw a chart that displays our sample regression line (by simply drawing blue line between data points with the lowest and highest $x$ value) and then show with red color lines where our regression line does not match up to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./regression-scatter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at that first red line.  It's showing that our regression formula does not perfectly predict our line.  More concretely, at that spot, $x = 100$, our regression line is predicting that the value of $y$ will be 250.  So our regression line is off. Even if we did not have our graph, we could see this by using our formula for the regression line $y = 1.5x + 100$.  Setting $x$ equal to 100, we see that $y = 1.5 * 100 + 100 = 250$.\n",
    "\n",
    "However the point below our regression line shows the actual value of y when x = 100 which is 150.  In other words, our regression line does not perfectly predict our data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each point where it is misses in it's prediction is called an error.  So that is what the reds lines are indictating, the distance between the prediction of made by our regression line and the actual data.  Or in other words, the red lines are visually displaying the size of each error.\n",
    "\n",
    "Now let's measure the size of that error.  We can say that our error, at point $x = 100$, is the actual $y$ minus expected $y$, which translates to $150 - 250 = -100$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining our Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using too many words to describe our earlier section.  And hopefully, by now you are beginning to believe that mathematical notation can help us speak about concepts with precision and clarity. \n",
    "\n",
    "One thing that's confusing about the above section is that we are really now talking about two things, our predicted $y$ values and our actual $y$ values.  Now so far we have defined our regression function as $y = mx + b$.  Where for a given value of $x$, we can calculate the value of $y$.  However, this value of $y$ is not the actual value of $y$, but just an estimation.  So let's indicate this, by changing our function to look like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\overline{y} = \\overline{m}x + \\overline{b}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those little dashes over the $y$, $m$ and $b$ are called hats, so this is read as y-hat equals m-hat times x plus b-hat.  These hats indicate that this formula does not give us the actual value of $y$, but simply our estimated value of $y$.  And that this predicted value of $y$ is based on our predicted values of $m$ and $b$. \n",
    "> Note that $x$ is not a predicted value.  Why is this?  Well, we are *providing* a value $x$, which in this case represents our movie budget, not predicting it.  So we are *providing* a value of $x$ and asking it to *predict* a value of $y$.  \n",
    "\n",
    "Now remember that we were given some real data as well.  This means that we have actual points for $x$ and $y$, which looks like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_show = {'x': 0, 'y': 100}\n",
    "second_show = {'x': 100, 'y': 150}\n",
    "third_show = {'x': 200, 'y': 600}\n",
    "fourth_show = {'x': 400, 'y': 700}\n",
    "\n",
    "shows = [first_show, second_show, third_show, fourth_show]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we represent our actual values of $x$, and $y$? Here's how: $y$.  No extra ink is needed.\n",
    "\n",
    "Ok, so now we know the following:  \n",
    " * **$y$**: actual y  \n",
    " * **$\\overline{y}$**: estimated y\n",
    " \n",
    "Now, using the Greek letter $\\varepsilon$, epsilon, to indicate error, we can say $\\varepsilon = y - \\overline{y}$.  Ok, so that is the general formula for error: $\\varepsilon$ = $y$ - $\\overline{y}$.  However, we can a little more precise by saying we are talking about error at any specific point, where $y$ and $\\overline{y}$ are at that same point.  This is written as: \n",
    "\n",
    "$\\varepsilon _{i}$ = $y_{i}$ - $\\overline{y}_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So given our dataset and our regression line, we can represent our error when $ x = 0 $ as  $\\varepsilon _{x=0} = y_{x=0}$ - $\\overline{y}_{x=0} = 100 - 100 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating and representing total error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now so far, we saw that we can calculate the error at a given value of $x$, $x_i$, by using the formula, $\\varepsilon_i$ = $y_i - \\overline{y_i}$.  And this helpful at describing how well our regression line predicts the value of $y$ at a specific point.  \n",
    "\n",
    "However, we want to see well our regression describes the relation between $x$ and $y$ in general - not just at a given point.  So let's move beyond calculating the error at a given point to describing the total error of the regression line from the actual data.  As an initial approach, we simply calculate the total error by summing the errors, $y - \\overline{y}$, for every point in our dataset.  \n",
    "\n",
    "Total Error = $\\sum_{i=1}^{n} y_i - \\overline{y_i}$\n",
    "\n",
    "However let's take another look at our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./regression-scatter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Take a look at what happens if we add the errors at $x = 100$ and $x = 200$. \n",
    "\n",
    "* $\\varepsilon_{x=100}= 150 - 250 = -100$\n",
    "* $\\varepsilon_{x=200} = 600 - 400 = 200$  \n",
    "* $\\varepsilon_{x=100} + \\varepsilon_{x=200} =  -150 + 200 = 50 $\n",
    "\n",
    "So because $\\varepsilon_{x=100}$ is positive while $ \\varepsilon_{x=200} $ is negative, adding the two errors  begins to cancel them out.  That's not what we want.  To represent our total error better, we can simply square the errors, so that we are always summing positive numbers.\n",
    "\n",
    "${\\varepsilon_i^2}$ = $({y_i - \\overline{y_i}})^2$\n",
    "\n",
    "Now given a list of points with coordinates (x, y), we can calculate the squared error of each of the points, and sum them up.  This is called our ** residual sum of squares ** (RSS).  Using our sigma notation, our formula RSS looks like: \n",
    "\n",
    "RSS $ = \\sum_{i = 1}^n ({y_i - \\overline{y_i}})^2$\n",
    "\n",
    "\n",
    "\n",
    "So let's apply this to our example.  In our example, we have actual $x$ and $y$ values at the following points: $ (0, 100), (100, 150), (200, 600), (400, 700) $.  And we can calculate the values of $\\overline{y} $ as $\\overline{y} = 1.5 *x + 100 $, for each of those four points.  So this gives us:\n",
    "\n",
    "RSS = $(0 - 0)^2 + (150 - 250)^2 + (600 - 400)^2 + (700 - 700)^2$ \n",
    "\n",
    "which reduces to  \n",
    "\n",
    "$-100^2 + 200^2 = 50,000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is great.  So now we have one number, RSS, that does a good job of representing how well our regression line fits the data.  We got there by calculating the errors at each of our provided points, and then squaring the errors so that our errors are always positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous to this lesson, we have simply assumed that our regression lines make \"good\" predictions of $y$ for given values of $x$.  In this lesson, we aimed to find a metric to tell us how well our regression line fits our actual data.  To do this, we started looking at an error at a given point, and describing that as the difference of the actual value of $y$ minus the value of $y$ expected from our regression line.  Then we saw how well our regression line describes the entire dataset by squaring the errors at each point (to eliminate negative errors), and adding these errors.  This is called the Residual Sum of Squares (RSS).  This is our metric for describing how well our regression line \"fits\" our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
